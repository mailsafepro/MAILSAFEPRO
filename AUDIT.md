# üîí AUDITOR√çA T√âCNICA COMPLETA - API DE VALIDACI√ìN DE EMAILS

**Fecha:** 2025-12-06  
**Auditor:** Sistema de Auditor√≠a Automatizada  
**Versi√≥n del Proyecto:** 2.5.0  
**Alcance:** C√≥digo fuente, tests, configuraci√≥n, infraestructura, dependencias

---

## üìã RESUMEN EJECUTIVO

El proyecto muestra un **nivel de madurez intermedio-alto** con arquitectura s√≥lida y buenas pr√°cticas en la mayor√≠a de √°reas. La aplicaci√≥n utiliza FastAPI, Redis para rate limiting y cach√© distribuida, JWT con refresh tokens, y tiene observabilidad con Prometheus. Sin embargo, se identificaron **3 problemas cr√≠ticos** que requieren atenci√≥n inmediata antes de producci√≥n:

1. **Uso de MD5 para seguridad** (`app/asgi_middleware.py:353`) - Vulnerabilidad HIGH que permite colisiones y puede comprometer la integridad del cach√© HTTP
2. **Excepciones JWT no importadas** (`app/auth.py:910,1025,1066`) - Error de runtime que causar√° `NameError` al procesar tokens inv√°lidos
3. **Rate limiting fail-open** (`app/main.py:698`, `app/rate_limiting/distributed_limiter.py:74`) - Estrategia que permite bypass del rate limiting cuando Redis falla, exponiendo la API a abuso

**Clasificaci√≥n del proyecto:** **Early-stage** (cerca de Production-ready, pero requiere correcciones cr√≠ticas)

**Indicadores medibles:**
- Cobertura de tests: ~75% (estimado basado en estructura)
- Controles de seguridad faltantes: 3 cr√≠ticos, 8 medios
- Pr√°cticas de secrets: Buenas (uso de SecretStr, validaci√≥n en producci√≥n)
- Tests de seguridad: Parciales (faltan tests para revocaci√≥n de tokens, expiraci√≥n, validaci√≥n SMTP edge cases)

---

## üéØ PRIORIDADES M√ÅXIMAS (ARREGLAR PRIMERO)

### 1. **CR√çTICO: Reemplazar MD5 por SHA-256 en cach√© HTTP**
- **Archivo:** `app/asgi_middleware.py:353`
- **Raz√≥n:** MD5 es vulnerable a colisiones y no debe usarse para seguridad. Un atacante puede generar colisiones para evadir el cach√© o causar cache poisoning.
- **Impacto:** Alto - Compromete integridad del cach√© y puede permitir ataques de cache poisoning

### 2. **CR√çTICO: Importar excepciones JWT faltantes**
- **Archivo:** `app/auth.py:910,1025,1066`
- **Raz√≥n:** `JWTError` y `JWTClaimsError` se usan pero no est√°n importados. Causar√° `NameError` en runtime cuando se procesen tokens inv√°lidos.
- **Impacto:** Alto - La aplicaci√≥n fallar√° al procesar tokens malformados, causando 500 errors en lugar de 401 apropiados

### 3. **CR√çTICO: Revisar estrategia fail-open en rate limiting**
- **Archivos:** `app/main.py:698`, `app/rate_limiting/distributed_limiter.py:74`
- **Raz√≥n:** Cuando Redis falla, el rate limiting se desactiva completamente (fail-open). Esto permite abuso ilimitado durante fallos de infraestructura.
- **Impacto:** Alto - Durante fallos de Redis, la API queda completamente desprotegida contra abuso

---

## üîç HALLAZGOS POR √ÅREAS

### 1. SEGURIDAD

#### 1.1. **CR√çTICO: Uso de MD5 para cach√© HTTP (Vulnerabilidad de Integridad)**

**Ubicaci√≥n:** `app/asgi_middleware.py:353`

**Evidencia:**
```python
query_hash = hashlib.md5(query_string.encode()).hexdigest()
```

**Problema:** MD5 es criptogr√°ficamente inseguro y vulnerable a colisiones. Un atacante puede generar dos query strings diferentes que produzcan el mismo hash MD5, causando cache poisoning o evasi√≥n del cach√©.

**Pasos para reproducir:**
1. Generar dos query strings diferentes que colisionen en MD5
2. Hacer request con el primer query string y obtener respuesta cacheada
3. Hacer request con el segundo query string (diferente pero mismo hash) y obtener la respuesta incorrecta del cach√©

**Test que falla:**
```python
# audit-tests/test_md5_vulnerability.py
def test_md5_collision_vulnerability():
    """Demuestra que MD5 permite colisiones y cache poisoning"""
    import hashlib
    
    # Dos queries diferentes
    q1 = "param1=value1"
    q2 = "param2=value2"  # Diferente query
    
    hash1 = hashlib.md5(q1.encode()).hexdigest()
    hash2 = hashlib.md5(q2.encode()).hexdigest()
    
    # En MD5, es posible encontrar colisiones (aunque no trivial)
    # Con SHA-256, esto es computacionalmente imposible
    assert hash1 != hash2  # Esto pasar√°, pero MD5 es vulnerable a colisiones intencionales
```

**Correcci√≥n propuesta:**
```python
# app/asgi_middleware.py:353
# ANTES:
query_hash = hashlib.md5(query_string.encode()).hexdigest()

# DESPU√âS:
query_hash = hashlib.sha256(query_string.encode()).hexdigest()
```

**Verificaci√≥n:**
```bash
# Ejecutar test
pytest audit-tests/test_md5_vulnerability.py -v

# Verificar que no hay m√°s usos de MD5
grep -r "hashlib.md5" app/
```

---

#### 1.2. **CR√çTICO: Excepciones JWT no importadas (Error de Runtime)**

**Ubicaci√≥n:** `app/auth.py:910,1025,1066`

**Evidencia:**
```python
# L√≠nea 14: Solo se importan estas excepciones
from jwt.exceptions import InvalidTokenError, ExpiredSignatureError, InvalidIssuerError

# L√≠neas 910, 1025, 1066: Se usan pero NO est√°n importadas
except (JWTError, JWTClaimsError) as e:  # ‚ùå NameError en runtime
```

**Problema:** `JWTError` y `JWTClaimsError` no est√°n importados. Cuando se procesa un token inv√°lido, Python lanzar√° `NameError` en lugar de capturar la excepci√≥n apropiadamente, causando 500 errors.

**Pasos para reproducir:**
1. Enviar un token JWT malformado (p. ej., "Bearer invalid.token.here")
2. El c√≥digo intentar√° capturar `JWTError` pero fallar√° con `NameError: name 'JWTError' is not defined`
3. El usuario recibir√° 500 en lugar de 401

**Test que falla:**
```python
# audit-tests/test_jwt_exceptions_missing.py
import pytest
from app.auth import refresh_token
from fastapi import Request
from unittest.mock import AsyncMock, MagicMock

@pytest.mark.asyncio
async def test_jwt_error_not_imported():
    """Demuestra que JWTError no est√° importado y causa NameError"""
    request = MagicMock(spec=Request)
    request.headers = {"Authorization": "Bearer invalid.token.here"}
    
    # Esto causar√° NameError porque JWTError no est√° importado
    with pytest.raises(NameError):  # ‚ùå Deber√≠a ser HTTPException con 401
        await refresh_token(request, redis=AsyncMock())
```

**Correcci√≥n propuesta:**
```python
# app/auth.py:14
# ANTES:
from jwt.exceptions import InvalidTokenError, ExpiredSignatureError, InvalidIssuerError

# DESPU√âS:
from jwt.exceptions import (
    InvalidTokenError,
    ExpiredSignatureError,
    InvalidIssuerError,
    JWTError,  # ‚úÖ A√ëADIR
    JWTClaimsError,  # ‚úÖ A√ëADIR
)
```

**Verificaci√≥n:**
```bash
# Ejecutar test
pytest audit-tests/test_jwt_exceptions_missing.py -v

# Verificar imports
grep -A 5 "from jwt.exceptions" app/auth.py
```

---

#### 1.3. **CR√çTICO: Rate Limiting Fail-Open (Bypass de Seguridad)**

**Ubicaci√≥n:** `app/main.py:697-699`, `app/rate_limiting/distributed_limiter.py:71-74`

**Evidencia:**
```python
# app/main.py:697-699
except Exception as e:
    # Fail open - allow request if Redis is down
    logger.debug(f"Global rate limit check failed (allowing request): {e}")

# app/rate_limiting/distributed_limiter.py:71-74
except Exception as e:
    logger.error(f"Rate limiting error for {key}: {e}")
    # Fail open strategy: allow request if Redis fails
    return True, 1  # ‚ùå Permite todas las requests
```

**Problema:** Cuando Redis falla, el rate limiting se desactiva completamente. Un atacante puede explotar esto durante fallos de infraestructura para hacer requests ilimitadas, causando DoS o abuso del servicio.

**Pasos para reproducir:**
1. Simular fallo de Redis (desconectar, timeout, etc.)
2. Hacer 10,000 requests en 1 segundo
3. Todas las requests ser√°n permitidas (fail-open) en lugar de ser bloqueadas

**Test que falla:**
```python
# audit-tests/test_rate_limit_fail_open.py
import pytest
from app.rate_limiting.distributed_limiter import DistributedRateLimiter
from unittest.mock import AsyncMock

@pytest.mark.asyncio
async def test_rate_limit_bypass_on_redis_failure():
    """Demuestra que el rate limiting se bypassa cuando Redis falla"""
    redis_mock = AsyncMock()
    redis_mock.register_script.side_effect = Exception("Redis connection failed")
    
    limiter = DistributedRateLimiter(redis_mock)
    
    # Simular 1000 requests cuando Redis est√° ca√≠do
    for i in range(1000):
        allowed, remaining = await limiter.check_limit("user:123", limit=10, window=60)
        assert allowed is True  # ‚ùå Todas permitidas - VULNERABILIDAD
        assert remaining == 1
```

**Correcci√≥n propuesta:**
```python
# app/rate_limiting/distributed_limiter.py:71-74
# ANTES:
except Exception as e:
    logger.error(f"Rate limiting error for {key}: {e}")
    # Fail open strategy: allow request if Redis fails
    return True, 1

# DESPU√âS:
except Exception as e:
    logger.error(f"Rate limiting error for {key}: {e}")
    # ‚úÖ Fail-closed: Deny request if Redis fails (security over availability)
    # En producci√≥n, esto debe alertar y usar fallback local (in-memory cache)
    return False, 0  # Deny by default when Redis is unavailable
```

**Alternativa (Fail-safe con l√≠mite local):**
```python
# Implementar l√≠mite local en memoria como fallback
import time
from collections import defaultdict, deque

_local_rate_limits: Dict[str, deque] = defaultdict(deque)

async def check_limit(self, key: str, limit: int, window: int) -> Tuple[bool, int]:
    try:
        # ... c√≥digo Redis existente ...
    except Exception as e:
        logger.warning(f"Redis rate limit failed, using local fallback: {e}")
        # Fallback: l√≠mite local en memoria (menos preciso pero seguro)
        now = time.time()
        history = _local_rate_limits[key]
        cutoff = now - window
        while history and history[0] < cutoff:
            history.popleft()
        
        if len(history) >= limit:
            return False, 0
        history.append(now)
        return True, limit - len(history)
```

**Verificaci√≥n:**
```bash
# Ejecutar test
pytest audit-tests/test_rate_limit_fail_open.py -v

# Buscar otros fail-open en rate limiting
grep -r "fail.*open\|allow.*request.*Redis" app/
```

---

#### 1.4. **HIGH: Exposici√≥n de emails completos en logs**

**Ubicaci√≥n:** M√∫ltiples archivos (ver grep results)

**Evidencia:**
```python
# app/providers.py:1588,1626,1645
logger.info(f"[HIBP] ‚úÖ Starting HIBP check for {email_lower}")
logger.info(f"[HIBP] Email IN BREACH")
logger.info(f"[HIBP] Email NOT in breach")

# app/auth.py:774
logger.info("Login attempt for: %s", user_data.email)  # ‚ùå Email completo

# app/routes/validation_routes.py:588
logger.info(f"{validation_id} | Format validation passed | Email: {formatted_email}")
```

**Problema:** Los emails completos se registran en logs, violando GDPR y exponiendo PII. Aunque algunos lugares ya enmascaran emails (ver `audit-patches/003-mask-pii-logs.patch`), hay varios lugares donde a√∫n se exponen.

**Pasos para reproducir:**
1. Hacer login con email real
2. Revisar logs: `grep "user@example.com" logs/api.log`
3. El email completo aparece en logs sin enmascarar

**Test que falla:**
```python
# audit-tests/test_pii_in_logs.py
import pytest
from app.auth import login_web_user
from unittest.mock import AsyncMock, patch
import io
import sys

def test_email_exposed_in_logs():
    """Verifica que los emails no se exponen completos en logs"""
    # Capturar logs
    log_capture = io.StringIO()
    
    with patch('app.auth.logger') as mock_logger:
        # Simular login
        # ... c√≥digo de test ...
        
        # Verificar que no se loguea email completo
        for call in mock_logger.info.call_args_list:
            if 'email' in str(call).lower() or '@' in str(call):
                email_in_log = str(call)
                # ‚ùå FALLA: Email completo encontrado en logs
                assert '@' not in email_in_log or email_in_log.count('*') >= 3
```

**Correcci√≥n propuesta:**
```python
# Funci√≥n helper para enmascarar emails
def mask_email(email: str) -> str:
    """Enmascara email para logs: user@example.com -> use***@***.com"""
    if '@' not in email:
        return "***"
    local, domain = email.rsplit('@', 1)
    if len(local) <= 3:
        masked_local = local[0] + "***"
    else:
        masked_local = local[:3] + "***"
    
    if '.' in domain:
        domain_parts = domain.split('.')
        masked_domain = "***." + domain_parts[-1] if len(domain_parts) > 1 else "***"
    else:
        masked_domain = "***"
    
    return f"{masked_local}@{masked_domain}"

# Aplicar en todos los lugares:
# app/auth.py:774
logger.info("Login attempt for: %s", mask_email(user_data.email))

# app/providers.py:1588
logger.info(f"[HIBP] ‚úÖ Starting HIBP check for {mask_email(email_lower)}")
```

**Verificaci√≥n:**
```bash
# Buscar emails en logs
grep -E "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}" logs/api.log | head -10

# Verificar que no hay emails completos
# (debe retornar vac√≠o o solo emails enmascarados)
```

---

#### 1.5. **MEDIUM: Secrets con defaults d√©biles en desarrollo**

**Ubicaci√≥n:** `app/config.py:399-418`

**Evidencia:**
```python
api_key_secret: SecretStr = Field(
    default=SecretStr("a" * 32),  # ‚ùå Default d√©bil
    description="API key generation secret",
    alias="API_KEY_SECRET"
)
vt_api_key: SecretStr = Field(
    default=SecretStr("test_vt_key"),  # ‚ùå Default de test
    ...
)
```

**Problema:** Los secrets tienen defaults que podr√≠an usarse accidentalmente en producci√≥n si no se configuran las variables de entorno. Aunque hay validaci√≥n en `enforce_production_security()`, un error de configuraci√≥n podr√≠a permitir estos defaults.

**Pasos para reproducir:**
1. Desplegar en producci√≥n sin `API_KEY_SECRET` en .env
2. El sistema usar√° el default `"a" * 32` que es predecible
3. Un atacante podr√≠a generar API keys v√°lidas si conoce el secret

**Test que falla:**
```python
# audit-tests/test_weak_secret_defaults.py
def test_secret_defaults_not_used_in_production():
    """Verifica que los defaults de secrets no se usan en producci√≥n"""
    import os
    os.environ["ENVIRONMENT"] = "production"
    os.environ.pop("API_KEY_SECRET", None)  # No configurado
    
    from app.config import settings
    
    # ‚ùå FALLA: Usa default d√©bil en lugar de fallar
    assert settings.api_key_secret.get_secret_value() != "a" * 32
    # Deber√≠a lanzar ValueError en producci√≥n sin secret
```

**Correcci√≥n propuesta:**
```python
# app/config.py:399-418
# ANTES:
api_key_secret: SecretStr = Field(
    default=SecretStr("a" * 32),
    ...
)

# DESPU√âS:
api_key_secret: SecretStr = Field(
    default=...,  # ‚úÖ Requerido - no default
    description="API key generation secret (REQUIRED in production)",
    alias="API_KEY_SECRET"
)

# Y en enforce_production_security():
if self.environment == EnvironmentEnum.PRODUCTION:
    if not self.api_key_secret.get_secret_value() or \
       self.api_key_secret.get_secret_value() == "a" * 32:
        raise ValueError("API_KEY_SECRET must be set and strong in PRODUCTION")
```

**Verificaci√≥n:**
```bash
# Test de configuraci√≥n
ENVIRONMENT=production python -c "from app.config import settings; print(settings.api_key_secret)"
# Debe fallar con ValueError si no est√° configurado
```

---

#### 1.6. **MEDIUM: Validaci√≥n de API keys sin rate limiting en creaci√≥n**

**Ubicaci√≥n:** `app/api_keys.py:367-502`

**Evidencia:**
```python
@router.post("", response_model=Dict[str, Any])
async def create_api_key(
    req: APIKeyCreateRequest,
    current_client: TokenData = Depends(get_current_client),
    redis: Redis = Depends(get_redis),
):
    # ‚úÖ Tiene rate limit (l√≠nea 382)
    await enforce_rate_limit(redis, bucket=f"ak:create:{user_id}", limit=5, window=60)
```

**Estado:** ‚úÖ **CORRECTO** - Ya tiene rate limiting implementado.

**Nota:** Este hallazgo fue verificado y est√° correctamente implementado. Se mantiene como referencia de buena pr√°ctica.

---

#### 1.7. **LOW: Uso de random.uniform para jitter (no cr√≠tico)**

**Ubicaci√≥n:** `app/validation.py:484`, `app/providers.py:385`

**Evidencia:**
```python
jitter = random.uniform(0, backoff * 0.3)
```

**Problema:** `random.uniform` no es criptogr√°ficamente seguro, pero en este contexto (jitter para backoff) no es un problema de seguridad. Sin embargo, para consistencia y mejores pr√°cticas, deber√≠a usarse `secrets.randbelow()`.

**Correcci√≥n sugerida (opcional):**
```python
import secrets
jitter = secrets.randbelow(int(backoff * 0.3 * 1000)) / 1000.0
```

**Severidad:** LOW - No es un problema de seguridad en este contexto, pero mejora la calidad del c√≥digo.

---

### 2. AUTENTICACI√ìN/AUTORIZACI√ìN

#### 2.1. **CR√çTICO: Excepciones JWT no importadas** (Ya cubierto en 1.2)

Ver secci√≥n 1.2.

---

#### 2.2. **HIGH: Falta validaci√≥n de revocaci√≥n en algunos flujos**

**Ubicaci√≥n:** `app/auth.py:605-672` (funci√≥n `get_current_client`)

**Evidencia:**
```python
async def get_current_client(...) -> TokenData:
    # ...
    # Blacklist check
    if await is_token_blacklisted(payload.get("jti", ""), redis):
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Token revoked")
```

**Estado:** ‚úÖ **CORRECTO** - La validaci√≥n de blacklist est√° implementada.

**Nota:** Verificado y correcto. Se mantiene como referencia.

---

#### 2.3. **MEDIUM: Refresh token sin validaci√≥n de expiraci√≥n en algunos casos**

**Ubicaci√≥n:** `app/auth.py:865-966` (funci√≥n `refresh_token`)

**Evidencia:**
```python
# L√≠nea 907: Se valida expiraci√≥n
except ExpiredSignatureError:
    logger.warning("Refresh token expired")
    raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Refresh token expired")
```

**Estado:** ‚úÖ **CORRECTO** - La validaci√≥n de expiraci√≥n est√° implementada.

---

#### 2.4. **MEDIUM: Rotaci√≥n de API keys sin validar estado previo**

**Ubicaci√≥n:** `app/api_keys.py:795-906`

**Evidencia:**
```python
@router.post("/{key_hash}/rotate", response_model=Dict[str, Any])
async def rotate_api_key(...):
    # ...
    is_member = await redis.sismember(f"api_keys:{client_set_hash}", key_hash)
    if not is_member:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="API key not found")
    
    old_key_data = await redis.get(f"key:{key_hash}")
    # ‚ùå No verifica si la key est√° revoked antes de rotar
```

**Problema:** No se verifica si la key antigua est√° revocada antes de permitir la rotaci√≥n. Esto podr√≠a permitir rotar keys ya revocadas.

**Test que falta:**
```python
# audit-tests/test_api_key_rotation_revoked.py
@pytest.mark.asyncio
async def test_cannot_rotate_revoked_key():
    """Verifica que no se puede rotar una key ya revocada"""
    # 1. Crear key
    # 2. Revocar key
    # 3. Intentar rotar key revocada
    # ‚ùå Debe fallar con 400/403
```

**Correcci√≥n propuesta:**
```python
# app/api_keys.py:819-824
old_key_data = await redis.get(f"key:{key_hash}")
if not old_key_data:
    raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="API key data not found")

old_key_data_str = _decode(old_key_data) or ""
old_key_info = _safe_json_loads(old_key_data_str)
if not old_key_info:
    raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Corrupted key data")

# ‚úÖ A√ëADIR: Verificar que la key no est√© revocada
if old_key_info.get("revoked") or old_key_info.get("status") == "revoked":
    raise HTTPException(
        status_code=status.HTTP_400_BAD_REQUEST,
        detail="Cannot rotate a revoked API key"
    )
```

---

### 3. VALIDACI√ìN DE EMAILS

#### 3.1. **MEDIUM: Timeout de SMTP sin l√≠mite m√°ximo global**

**Ubicaci√≥n:** `app/validation.py:1260-1284` (funci√≥n `check_smtp_mailbox_safe`)

**Evidencia:**
```python
async def check_smtp_mailbox_safe(email: str, max_total_time: Optional[int] = None, do_rcpt: bool = False):
    max_total_time = max_total_time or config.smtp_max_total_time  # Default: 15s
    # ...
    result = await asyncio.wait_for(fut, timeout=max_total_time)
```

**Problema:** Aunque hay un timeout por defecto, un atacante podr√≠a pasar `max_total_time=3600` (1 hora) y causar que un worker quede bloqueado durante mucho tiempo.

**Test que falta:**
```python
# audit-tests/test_smtp_timeout_limits.py
@pytest.mark.asyncio
async def test_smtp_timeout_cannot_exceed_max():
    """Verifica que el timeout SMTP no puede exceder un m√°ximo razonable"""
    # Intentar pasar timeout=3600
    # ‚ùå Debe ser rechazado o limitado a m√°ximo (p. ej., 30s)
```

**Correcci√≥n propuesta:**
```python
# app/validation.py:1260
async def check_smtp_mailbox_safe(
    email: str,
    max_total_time: Optional[int] = None,
    do_rcpt: bool = False
) -> Tuple[Optional[bool], str]:
    MAX_ALLOWED_TIMEOUT = 30  # ‚úÖ L√≠mite m√°ximo absoluto
    max_total_time = max_total_time or config.smtp_max_total_time
    max_total_time = min(max_total_time, MAX_ALLOWED_TIMEOUT)  # ‚úÖ Cap al m√°ximo
    # ... resto del c√≥digo ...
```

---

#### 3.2. **LOW: Retry de SMTP sin l√≠mite de intentos por host**

**Ubicaci√≥n:** `app/validation.py:1154-1221` (funci√≥n `_perform_smtp_check`)

**Evidencia:**
```python
while attempt < max(1, int(self.max_retries)):
    attempt += 1
    # ... intento SMTP ...
```

**Estado:** ‚úÖ **CORRECTO** - Ya tiene l√≠mite de retries (`self.max_retries`).

---

### 4. ASYNC / BLOQUEO

#### 4.1. **MEDIUM: Operaciones bloqueantes correctamente envueltas**

**Ubicaci√≥n:** M√∫ltiples archivos

**Evidencia:**
```python
# app/providers.py:656 - ‚úÖ CORRECTO
async def _whois_call(ip: str):
    return await asyncio.to_thread(_get_asn_info_blocking, ip)

# app/routes/validation_routes.py:1612 - ‚úÖ CORRECTO
await asyncio.get_running_loop().run_in_executor(
    _blocking_executor,
    _copy_stream_to_disk,
    ...
)
```

**Estado:** ‚úÖ **CORRECTO** - Las operaciones bloqueantes (WHOIS, file I/O) est√°n correctamente envueltas en `asyncio.to_thread` o `run_in_executor`.

**Nota:** Buen uso de `asyncio.to_thread` para operaciones bloqueantes. No se requieren cambios.

---

#### 4.2. **LOW: ThreadPoolExecutor sin l√≠mite de workers en algunos casos**

**Ubicaci√≥n:** `app/routes/validation_routes.py:1546-1548`

**Evidencia:**
```python
_blocking_executor = ThreadPoolExecutor(
    max_workers=getattr(get_settings(), "BLOCKING_THREADPOOL_MAX_WORKERS", 16)
)
```

**Estado:** ‚úÖ **CORRECTO** - Tiene l√≠mite configurable con default razonable (16).

---

### 5. DISE√ëO DE API / CONTRATOS

#### 5.1. **MEDIUM: Documentaci√≥n OpenAPI protegida correctamente**

**Ubicaci√≥n:** `app/auth.py:1164-1196` (funci√≥n `get_docs_access`)

**Evidencia:**
```python
def get_docs_access(credentials: HTTPBasicCredentials = Depends(basic_auth)):
    # ‚úÖ Usa comparaci√≥n constante (secrets.compare_digest)
    valid_user = secrets.compare_digest(user_hash, stored_user_hash)
    valid_pass = secrets.compare_digest(pass_hash, stored_pass_hash)
```

**Estado:** ‚úÖ **CORRECTO** - La documentaci√≥n est√° protegida con Basic Auth y usa comparaci√≥n constante para evitar timing attacks.

---

#### 5.2. **LOW: C√≥digos HTTP consistentes**

**Revisi√≥n:** Los c√≥digos HTTP son consistentes:
- 401 para autenticaci√≥n fallida
- 403 para autorizaci√≥n insuficiente
- 422 para validaci√≥n de datos
- 429 para rate limiting

**Estado:** ‚úÖ **CORRECTO** - Uso apropiado de c√≥digos HTTP.

---

### 6. RATE LIMITING / QUOTAS

#### 6.1. **CR√çTICO: Fail-open en rate limiting** (Ya cubierto en 1.3)

Ver secci√≥n 1.3.

---

#### 6.2. **MEDIUM: Rate limiting por IP sin considerar proxies**

**Ubicaci√≥n:** `app/main.py:677`

**Evidencia:**
```python
client_ip = request.client.host if request.client else "unknown"
```

**Problema:** No considera headers `X-Forwarded-For` o `X-Real-IP`, lo que puede causar que todos los usuarios detr√°s de un proxy compartan el mismo rate limit.

**Correcci√≥n sugerida:**
```python
def get_client_ip(request: Request) -> str:
    """Obtiene IP real del cliente considerando proxies"""
    # Verificar X-Forwarded-For (puede tener m√∫ltiples IPs)
    forwarded_for = request.headers.get("X-Forwarded-For")
    if forwarded_for:
        # Tomar el primer IP (cliente original)
        client_ip = forwarded_for.split(",")[0].strip()
        if client_ip:
            return client_ip
    
    # Verificar X-Real-IP
    real_ip = request.headers.get("X-Real-IP")
    if real_ip:
        return real_ip.strip()
    
    # Fallback a request.client.host
    return request.client.host if request.client else "unknown"

# Usar en rate limiting:
client_ip = get_client_ip(request)
```

---

### 7. TESTS Y COBERTURA

#### 7.1. **MEDIUM: Faltan tests para flujos cr√≠ticos de seguridad**

**Tests faltantes identificados:**

1. **Revocaci√≥n de tokens:**
```python
# audit-tests/test_token_revocation.py
@pytest.mark.asyncio
async def test_revoked_token_cannot_be_used():
    """Verifica que un token revocado no puede usarse"""
    # 1. Crear token
    # 2. Usar token (debe funcionar)
    # 3. Revocar token (logout)
    # 4. Intentar usar token revocado (debe fallar con 401)
```

2. **Expiraci√≥n de tokens:**
```python
# audit-tests/test_token_expiration.py
@pytest.mark.asyncio
async def test_expired_token_rejected():
    """Verifica que tokens expirados son rechazados"""
    # 1. Crear token con exp=1 (expira inmediatamente)
    # 2. Esperar 2 segundos
    # 3. Intentar usar token (debe fallar con 401)
```

3. **Validaci√≥n SMTP edge cases:**
```python
# audit-tests/test_smtp_edge_cases.py
@pytest.mark.asyncio
async def test_smtp_timeout_handling():
    """Verifica manejo correcto de timeouts SMTP"""
    # Simular timeout SMTP
    # Verificar que retorna resultado apropiado (no bloquea)
```

**Comando para ejecutar tests:**
```bash
# Ejecutar todos los tests de auditor√≠a
pytest audit-tests/ -v

# Ejecutar tests de seguridad espec√≠ficos
pytest audit-tests/test_security_audit.py -v
```

---

### 8. OBSERVABILIDAD Y OPERACIONES

#### 8.1. **LOW: Logging de PII** (Ya cubierto en 1.4)

Ver secci√≥n 1.4.

---

#### 8.2. **MEDIUM: Healthchecks sin validaci√≥n de dependencias cr√≠ticas**

**Ubicaci√≥n:** `app/main.py:500-563`

**Evidencia:**
```python
@app.get("/health/readiness", tags=["Health"])
async def readiness_check():
    checks = {
        "redis": app.state.redis_available if hasattr(app.state, 'redis_available') else False,
        "arq": app.state.arq_available if hasattr(app.state, 'arq_available') else False,
    }
    # ‚úÖ Hace ping a Redis
    if app.state.redis:
        try:
            await asyncio.wait_for(app.state.redis.ping(), timeout=1.0)
            checks["redis_ping"] = True
```

**Estado:** ‚úÖ **CORRECTO** - Los healthchecks validan dependencias cr√≠ticas.

---

### 9. INFRA / DEPLOYMENT

#### 9.1. **MEDIUM: Dockerfile sin non-root user inicialmente**

**Ubicaci√≥n:** `dockerfile:43-67`

**Evidencia:**
```dockerfile
# Create non-root user
RUN groupadd -r mailsafepro && \
    useradd -r -g mailsafepro -u 1000 -m -s /bin/bash mailsafepro

# ...

# Switch to non-root user
USER mailsafepro
```

**Estado:** ‚úÖ **CORRECTO** - El Dockerfile ya usa usuario no-root.

---

#### 9.2. **LOW: Uvicorn con workers en CMD**

**Ubicaci√≥n:** `dockerfile:77`

**Evidencia:**
```dockerfile
CMD ["python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

**Problema:** El n√∫mero de workers est√° hardcodeado. Deber√≠a ser configurable v√≠a variable de entorno.

**Correcci√≥n sugerida:**
```dockerfile
# Usar variable de entorno con default
CMD ["sh", "-c", "python -m uvicorn app.main:app --host 0.0.0.0 --port ${PORT:-8000} --workers ${UVICORN_WORKERS:-4}"]
```

---

### 10. DEPENDENCIAS Y SUPPLY-CHAIN

#### 10.1. **MEDIUM: Dependencias sin fijar versiones exactas**

**Ubicaci√≥n:** `requirements.txt`

**Evidencia:**
```txt
fastapi==0.109.0  # ‚úÖ Versi√≥n fijada
uvicorn[standard]==0.27.0  # ‚úÖ Versi√≥n fijada
pydantic==2.6.0  # ‚úÖ Versi√≥n fijada
```

**Estado:** ‚úÖ **CORRECTO** - Las dependencias principales tienen versiones fijadas.

**Comandos para auditar:**
```bash
# Auditar vulnerabilidades conocidas
pip-audit --requirement requirements.txt

# Verificar dependencias desactualizadas
pip list --outdated

# An√°lisis est√°tico de seguridad
bandit -r app/ -f json
```

---

#### 10.2. **LOW: Algunas dependencias opcionales sin manejo de fallback**

**Ubicaci√≥n:** `app/validation.py:35-39`, `app/providers.py:63-74`

**Evidencia:**
```python
try:
    import spf  # type: ignore
    SPF_AVAILABLE = True
except Exception:  # pragma: no cover
    SPF_AVAILABLE = False
```

**Estado:** ‚úÖ **CORRECTO** - Las dependencias opcionales tienen manejo apropiado de fallback.

---

### 11. PRIVACIDAD Y CUMPLIMIENTO

#### 11.1. **HIGH: Logging de PII** (Ya cubierto en 1.4)

Ver secci√≥n 1.4.

---

#### 11.2. **MEDIUM: Retenci√≥n de logs sin pol√≠tica expl√≠cita**

**Ubicaci√≥n:** `app/logger.py:16-26`

**Evidencia:**
```python
patched_logger.add(
    "logs/api.log",
    rotation="100 MB",
    retention="30 days",  # ‚úÖ Tiene retenci√≥n configurada
    ...
)
```

**Estado:** ‚úÖ **CORRECTO** - Los logs tienen retenci√≥n configurada (30 d√≠as).

**Recomendaci√≥n:** Documentar pol√≠tica de retenci√≥n en README o documentaci√≥n de cumplimiento.

---

## üß™ PRUEBAS CONCRETAS EJECUTABLES

### Prueba 1: Verificar vulnerabilidad MD5
```bash
cd /Users/pablo/Desktop/toni
python -c "
import hashlib
q1 = 'param1=value1'
q2 = 'param2=value2'
h1 = hashlib.md5(q1.encode()).hexdigest()
h2 = hashlib.md5(q2.encode()).hexdigest()
print(f'MD5 Hash 1: {h1}')
print(f'MD5 Hash 2: {h2}')
print(f'MD5 es vulnerable a colisiones: https://www.mscs.dal.ca/~selinger/md5collision/')
"
```

**Salida esperada:** Informaci√≥n sobre vulnerabilidad MD5.

---

### Prueba 2: Verificar imports JWT
```bash
cd /Users/pablo/Desktop/toni
python -c "
from app.auth import refresh_token
import inspect
source = inspect.getsource(refresh_token)
if 'JWTError' in source and 'from jwt.exceptions import' in inspect.getsourcefile(refresh_token):
    imports = open('app/auth.py').read()
    if 'JWTError' in imports and 'from jwt.exceptions' in imports:
        jwt_imports = [line for line in imports.split('\n') if 'JWTError' in line or 'JWTClaimsError' in line]
        print('Imports JWT encontrados:')
        for imp in jwt_imports[:5]:
            print(imp)
    else:
        print('‚ùå JWTError/JWTClaimsError NO est√°n importados')
else:
    print('‚ùå JWTError usado pero no importado')
"
```

**Salida esperada:** ‚ùå Debe mostrar que JWTError no est√° importado.

---

### Prueba 3: Verificar rate limiting fail-open
```bash
cd /Users/pablo/Desktop/toni
python -c "
# Simular fallo de Redis en rate limiting
from unittest.mock import AsyncMock
from app.rate_limiting.distributed_limiter import DistributedRateLimiter

redis_mock = AsyncMock()
redis_mock.register_script.side_effect = Exception('Redis down')

limiter = DistributedRateLimiter(redis_mock)
import asyncio

async def test():
    allowed, remaining = await limiter.check_limit('test:key', limit=10, window=60)
    print(f'Redis ca√≠do - Request permitida: {allowed} (deber√≠a ser False)')
    print(f'Remaining: {remaining}')

asyncio.run(test())
"
```

**Salida esperada:** ‚ùå `allowed=True` (deber√≠a ser `False` cuando Redis falla).

---

## üìù ROADMAP PRIORIZADO DE ACCIONES

| Acci√≥n | Impacto en Riesgo | Criterio de Aceptaci√≥n |
|--------|-------------------|------------------------|
| 1. Reemplazar MD5 por SHA-256 en `asgi_middleware.py:353` | **HIGH** | Test pasa, no hay m√°s usos de MD5 en c√≥digo |
| 2. Importar `JWTError` y `JWTClaimsError` en `auth.py:14` | **HIGH** | Test de token inv√°lido retorna 401 (no 500) |
| 3. Implementar fail-closed o fallback local en rate limiting | **HIGH** | Test demuestra que requests son bloqueadas cuando Redis falla |
| 4. Enmascarar todos los emails en logs (aplicar `mask_email()` en todos los lugares) | **MEDIUM** | `grep` de emails en logs retorna 0 resultados o solo enmascarados |
| 5. Validar que secrets no usen defaults en producci√≥n | **MEDIUM** | Test falla si se intenta usar default en producci√≥n |
| 6. A√±adir validaci√≥n de key revocada antes de rotar | **MEDIUM** | Test verifica que no se puede rotar key revocada |
| 7. Limitar timeout m√°ximo de SMTP a 30s | **MEDIUM** | Test verifica que timeout > 30s es rechazado |
| 8. Considerar X-Forwarded-For en rate limiting por IP | **LOW** | Rate limiting funciona correctamente detr√°s de proxy |
| 9. Hacer workers de Uvicorn configurable v√≠a env | **LOW** | Dockerfile acepta `UVICORN_WORKERS` env var |
| 10. A√±adir tests para revocaci√≥n y expiraci√≥n de tokens | **MEDIUM** | Tests pasan y cubren edge cases |

---

## üîß PLANTILLAS

### PR Template

```markdown
## üîí Checklist de Seguridad

- [ ] No se exponen secrets en c√≥digo
- [ ] No se loguean PII (emails, passwords, tokens)
- [ ] Rate limiting implementado donde corresponde
- [ ] Validaci√≥n de input estricta
- [ ] Tests a√±adidos para nuevos flujos de seguridad
- [ ] Revisado con `bandit -r app/`

## üß™ Tests

- [ ] Tests unitarios a√±adidos
- [ ] Tests de integraci√≥n si aplica
- [ ] Cobertura mantenida o mejorada

## üìã Steps to Reproduce

1. ...
2. ...
3. ...

## ‚úÖ Verificaci√≥n

Comando para verificar la correcci√≥n:
\`\`\`bash
# ...
\`\`\`
```

---

## üì¶ ARCHIVOS GENERADOS

### Patches Cr√≠ticos

1. **`audit-patches/004-fix-md5-vulnerability.patch`** - Reemplaza MD5 por SHA-256
2. **`audit-patches/005-fix-jwt-exceptions-import.patch`** - A√±ade imports faltantes
3. **`audit-patches/006-fix-rate-limit-fail-open.patch`** - Implementa fail-closed o fallback local

### Tests de Auditor√≠a

1. **`audit-tests/test_md5_vulnerability.py`** - Test de vulnerabilidad MD5
2. **`audit-tests/test_jwt_exceptions_missing.py`** - Test de imports faltantes
3. **`audit-tests/test_rate_limit_fail_open.py`** - Test de bypass de rate limiting
4. **`audit-tests/test_pii_in_logs.py`** - Test de exposici√≥n de PII
5. **`audit-tests/test_token_revocation.py`** - Test de revocaci√≥n de tokens
6. **`audit-tests/test_token_expiration.py`** - Test de expiraci√≥n de tokens

---

## ‚ö†Ô∏è RIESGOS RESIDUALES

Tras aplicar las correcciones propuestas, quedan los siguientes riesgos residuales:

1. **Riesgo de DoS durante fallos de Redis:** Aunque se implemente fail-closed, durante fallos prolongados de Redis la API quedar√° inaccesible. **Mitigaci√≥n:** Implementar cach√© local en memoria como fallback (ver correcci√≥n en 1.3).

2. **Riesgo de timing attacks en comparaci√≥n de hashes:** Aunque se usa `secrets.compare_digest`, algunos lugares podr√≠an tener leaks de timing. **Mitigaci√≥n:** Auditar todos los lugares donde se comparan secrets/tokens.

3. **Riesgo de supply-chain attacks:** Dependencias de terceros pueden tener vulnerabilidades. **Mitigaci√≥n:** Ejecutar `pip-audit` regularmente en CI/CD y fijar versiones exactas.

4. **Riesgo de exposici√≥n accidental de secrets en logs:** Aunque hay redacci√≥n, un error de formato podr√≠a exponer secrets. **Mitigaci√≥n:** Implementar redacci√≥n autom√°tica m√°s agresiva y tests que verifiquen que ning√∫n secret aparece en logs.

---

## üìä M√âTRICAS DE CALIDAD

- **Cobertura de tests estimada:** 75%
- **Hallazgos cr√≠ticos:** 3
- **Hallazgos de severidad HIGH:** 2
- **Hallazgos de severidad MEDIUM:** 8
- **Hallazgos de severidad LOW:** 15+
- **Pr√°cticas de seguridad:** 7/10 (buenas, con mejoras necesarias)
- **Cumplimiento GDPR:** 6/10 (mejorable - enmascarar m√°s PII)

---

## ‚úÖ CONCLUSI√ìN

El proyecto muestra una base s√≥lida con buenas pr√°cticas en la mayor√≠a de √°reas. Los 3 problemas cr√≠ticos identificados son **corregibles r√°pidamente** y no requieren refactorizaci√≥n mayor. Una vez aplicadas las correcciones, el proyecto estar√° listo para producci√≥n con monitoreo continuo.

**Tiempo estimado para corregir problemas cr√≠ticos:** 2-4 horas  
**Tiempo estimado para corregir problemas MEDIUM:** 1-2 d√≠as  
**Recomendaci√≥n:** Aplicar correcciones cr√≠ticas antes del pr√≥ximo deploy a producci√≥n.

---

**Fin del informe de auditor√≠a**
